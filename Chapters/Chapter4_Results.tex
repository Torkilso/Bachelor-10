\chapter{Results}
\lhead{\emph{Results}}

\section{Scientific results}
This section will contain data, visualizations and results from our work towards our scientific problem.  

In order to evaluate the different ANN models against each other, each model classified three different datasets every iteration of training (epoch). Every training session therefore includes three different accuracies. These accuracies are calculated as $\frac{correct\  predictions}{total\ predictions}$.  

The first dataset is the training set. This dataset consists of a large subset of data gathered from the CHROME dataset (90\%), and is the data the models used as training data. This dataset is labeled as \textit{train} in the accuracy graphs below.

The second dataset is the validation set, also called the test set. This dataset consists of the last 10\% of data from the CHROME dataset. When evaluating the models on different dataset sizes, the total size is written in the title of the accuracy graphs. This total is then split 90/10, where 90\% of the data was included in the training set, and 10\% was included in the validation set. None of the data in the validation set was used during training, and this data is therefore a good representation for how the model performs on unseen data. This dataset is labeled as \textit{test} in the accuracy graphs below.

The third dataset is a set of real data gathered from the example website, with symbols written by a few different people. This dataset is used to give an indication of the correctness of the preprocessing (as the data is from another source), as well as how the model responds to data from another source. The real dataset was an important inclusion because the main goal of this assignment was to produce good results under circumstances simulated by the example website. Notice that this dataset included a few mislabeled data points, contained only about three hundred data points, and includes only a subset of all the classes. The dataset is therefore only used as an indication of the accuracy on real data. This dataset is labeled as \textit{real} in the accuracy graphs below.

%TODO her må vi forklare hva train test og real er.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{Assets/Chapter4_Result/CNN_40_epoch.png}
    \caption{Training accuracy from the CNN model with 44000 data points evaluated for 40 epochs.}
    \label{fig:CNN_44000}
\end{figure}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{Assets/Chapter4_Result/RNN_40_epoch.png}
    \caption{Training accuracy from the RNN model with 44000 data points evaluated for 40 epochs.}
    \label{fig:RNN_44000}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=.8\linewidth]{Assets/Chapter4_Result/Combined_CNN_and_RNN_40_epoch.png}
    \caption{Training accuracy from the combined CNN and RNN model with 44000 datapoints. Evaluated for 40 epochs.}
    \label{fig:combined_CNN_RNN_44000}
\end{figure}

The tables below show the same data in tabular form. Each row is a snapshot of the different models' accuracy in percent at specific epochs. 

Table of the \textbf{train} dataset.
\begin{figure}[H]
    \centering
        \begin{tabular}{| p{2cm} | p{3cm} | p{3cm} | p{3cm} |}
    \hline
    Epoch & \textbf{CNN} & \textbf{RNN} & \textbf{Combined} \\ \hline
    10 & 97.66 & 93.99 & 97.53 \\ \hline
    20 & 98.43 & 94.87 & 98.08 \\ \hline
    30 & 98.81 & 95.62 & 98.44 \\ \hline
    40 & 98.86 & 95.95 & 98.46 \\ \hline
    \end{tabular}
    \caption{Snapshot of accuracy in percent on the train dataset for all models at epoch number 10, 20, 30 and 40}

    \label{fig:table_train_dataset}
\end{figure}

Table of the \textbf{test} dataset.
\begin{figure}[H]
    \centering
    \begin{tabular}{| p{2cm} | p{3cm} | p{3cm} | p{3cm} |}
    \hline
    Epoch & \textbf{CNN} & \textbf{RNN} & \textbf{Combined} \\ \hline
    10 & 95.48 & 96.82 & 98.07 \\ \hline
    20 & 95.29 & 97.31 & 98.13 \\ \hline
    30 & 95.98 & 97.46 & 98.13 \\ \hline
    40 & 96.51 & 97.35 & 98.28 \\ \hline
    \end{tabular}
    \caption{Snapshot of accuracy in percent on the test dataset for all models at epoch number 10, 20, 30 and 40}
    \label{fig:table_test_dataset}

\end{figure}

Table of the \textbf{real} dataset.
\begin{figure}[H]
    \centering
    \begin{tabular}{| p{2cm} | p{3cm} | p{3cm} | p{3cm} |}
    \hline
    Epoch & \textbf{CNN} & \textbf{RNN} & \textbf{Combined} \\ \hline
    10 & 89.75 & 88.99 & 94.12 \\ \hline
    20 & 88.24 & 94.88 & 96.20 \\ \hline
    30 & 92.41 & 93.93 & 95.83 \\ \hline
    40 & 91.08 & 94.50 & 96.02 \\ \hline
    \end{tabular}
    \caption{Snapshot of accuracy in percent on the real dataset for all models at epoch number 10, 20, 30 and 40}
    \label{fig:table_real_dataset}

\end{figure}

\section{Engineering results}
This section will contain how our example project/proof of concept has turned out in terms of goals set in earlier stages of the project. Since the project is not a traditional software engineering bachelors project evaluation in this section of the project is based on the goals set in some of the meetings with the product owners. % Resultat fra tester skal være lagt her
%
The engineering goal in this project was to create a proof of concept application which can display the potential of a handwriting recognition system for mathematical symbols. In the initial meetings with the product owners they concluded with that they were hoping to get an application/module that would enhance Matistikk. 
% 

% 
\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{Assets/Chapter4_Result/predictor_example.png}
    \caption{Example of the graphical user interface. A simple HTML5 canvas is used to perform input, currently it does a HTTP post request to a back end to perform classification of buffer. The HTTP post method could be swapped with a WebSocket. The result is shown at the top right corner in human readable form, directly under the result is the result in \LaTeX, this is useful to further use it in some other API, for example Wolfram Alpha. Under the \LaTeX  is the probabilities of either a chosen symbol or the latest drawn.}
    \label{fig:predictor_example}
\end{figure}
In addition to being quite simple but functional, we have made choices on both back- and front-end code to make it modular and simple to integrate into a system. An example implementation of the proof of concept application is deployed on Heroku, a cloud application platform.

\subsection{User Interface}
% TODO brukertest osv




\section{Administrative results}
This section will contain results from an administrative perspective. This includes the planning, implementation and achievements of project goals.
\quad
The nature of this assignment led the project first into a software development phase, closely followed by a research phase. Both phases was highly influenced by an agile mindset, although the software development phase was actually planned with sprints and reviews. Attempts were made on planning the research phase, but much of the time went into knowing artificial neural networks. \\
In the software development phase an agile mindset was always in the background, every critical decision and choice was discussed, this was an important aspect of the teamwork. The project needed an quick mindset, new ideas were coming along all the time, but we would have to discard them before wasting too much time. This was only possible through our good cooperation and stand-up/status meetings each day. \\
Even though we call our phases software development and research it is important to understand the dynamic mindset behind this project, we would always think about new improvements to software even though we were deeply invested in some other issue. This constant chase of continuous improvement made the project as dynamic as necessary. % TODO review dette, semi ok ?


